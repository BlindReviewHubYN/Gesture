{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pD4ob-YjNk8i"
      },
      "outputs": [],
      "source": [
        "openai_key = \"\" ## Please change it to your key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "U_mOzmVuNs_y"
      },
      "outputs": [],
      "source": [
        "## Comment this out if you run on colab\n",
        "##!pip install openai \n",
        "##!pip install backoff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GxV42TtZNy45"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import random\n",
        "import backoff\n",
        "\n",
        "openai.api_key = openai_key\n",
        "random.seed(777)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEQbs7WjN5Hr",
        "outputId": "c94acdb4-a5a2-48b1-c536-c333f9466826"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Hello! How can I assist you today?']\n",
            "['Hello! How can I help you today? If you have any questions or need assistance, feel free to ask.']\n"
          ]
        }
      ],
      "source": [
        "## We do not use System Message here and only test gpt-3.5 and gpt-4 but the code is compatible to the old models\n",
        "## We test the snapshot so that the results are reproducible.\n",
        "## The model are \"text-davinci-003\", \"gpt-3.5-turbo\", \"gpt-4\"\n",
        "models = [\"text-davinci-003\", \"gpt-3.5-turbo\", \"gpt-4\"]\n",
        "D003 = \"text-davinci-003\"\n",
        "CHATGPT = \"gpt-3.5-turbo\"\n",
        "GPT4 = \"gpt-4\"\n",
        "\n",
        "## Backofff for chat since both chatgpt and gpt-4 are always heavy used.\n",
        "@backoff.on_exception(backoff.expo, openai.error.RateLimitError, max_time=6000)\n",
        "def completions_with_backoff(**kwargs):\n",
        "    return openai.Completion.create(**kwargs)\n",
        "\n",
        "@backoff.on_exception(backoff.expo, openai.error.RateLimitError, max_time=6000)\n",
        "def chat_completions_with_backoff(**kwargs):\n",
        "    return openai.ChatCompletion.create(**kwargs)\n",
        "\n",
        "def gptQuery(prompt, model, temperature = 0, n=1, logprobs=1, echo = False, **kwargs):\n",
        "  if model == models[0]:\n",
        "    out=completions_with_backoff(model=model, \n",
        "                               prompt=prompt, \n",
        "                               logprobs=logprobs, \n",
        "                               temperature=temperature, max_tokens = 500,\n",
        "                               n = n, **kwargs)\n",
        "    if echo: print(out)\n",
        "    return [response.text.strip() for response in out.choices ]\n",
        "  if model == models[1] or model == models[2]:\n",
        "    out = chat_completions_with_backoff(model=model,\n",
        "                                     messages=[{\"role\":\"user\",\"content\":prompt}], \n",
        "                                     temperature=temperature, max_tokens = 500,\n",
        "                                     n=n)\n",
        "    if echo: print(out) \n",
        "    return [response.message.content.strip() for response in out.choices ]\n",
        "\n",
        "## Test that the openAIkey is working correctly\n",
        "## print(gptQuery(prompt = \"Hello Test Test\", model=models[0]))\n",
        "print(gptQuery(prompt = \"Hello Test Test\", model=models[1]))\n",
        "print(gptQuery(prompt = \"Hello Test Test\", model=models[2]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Reading the annotation\n",
        "df = pd.read_csv(\"Obama_annotations_v7.csv\")\n",
        "\n",
        "## New combined variables\n",
        "df['ContainerMovement'] = df['ContainerMovement'].fillna(\"\")\n",
        "df['PhysicalGesture'] = df['GestureType']\n",
        "for i in df.index:\n",
        "    #if df['GestureType'][i] == \"container\" and df[\"ContainerMovement\"][i] != \"\":\n",
        "    #    df.loc[i, 'PhysicalGesture'] = df[\"ContainerMovement\"][i] + \" \" + df['GestureType'][i]\n",
        "    if df['GestureType'][i] == \"sweep\":\n",
        "        df.loc[i, 'PhysicalGesture']= \"palm \" + df[\"HandPlane\"][i] + \" \" + df['GestureType'][i]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_sweep = df[df['GestureType'] == \"sweep\"].copy()\n",
        "df_sweep.index = range(df_sweep.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "def genPrompt(dat, i, output, num_examples, examples = [], context = False, fillin=False):\n",
        "    ## dat = data, i = index of question to be predicted \n",
        "    ## output =  expected output. Format is a list. If more than one, the output will be concated and separated by comma\n",
        "    ## num_example = number of examples of each gesturetype. -1 for all except itself.\n",
        "    ## full_utterance if true will append the full utterance to each example \n",
        "    ## i.e., \"full utterarance\", \"utterance\" : \"output\" \n",
        "    \n",
        "    ## Instruction:     \n",
        "    out = \"Barrack Obama is giving a speech at Democratic National Convention.\\n\" if context else \"A man is giving a speech.\\n\"\n",
        "\n",
        "    if num_examples == - 1:\n",
        "        examples = list(range(dat.shape[0]))\n",
        "        examples.remove(i)\n",
        "\n",
        "    ##Add n gesturetype that is not equal to i in order\n",
        "    if(len(examples)==0):\n",
        "        span_ind = [ind for ind in dat.index[dat[\"GestureType\"] == \"span\"].to_list() if ind != i ]\n",
        "        sweep_ind = [ind for ind in dat.index[dat[\"GestureType\"] == \"sweep\"].to_list() if ind != i]\n",
        "        container_ind = [ind for ind in dat.index[dat[\"GestureType\"] == \"container\"].to_list() if ind != i]\n",
        "        for j in range(num_examples):\n",
        "            examples.append(span_ind[j])\n",
        "            examples.append(sweep_ind[j])\n",
        "            examples.append(container_ind[j])\n",
        "    examples.sort()\n",
        "    for ind in examples: \n",
        "        if not fillin: \n",
        "            out += 'He said \"' + dat[\"utteranceLong\"][ind] + '\" When he said \"' + dat[\"utterance\"][ind] + '\", he used the following gesture: ' + dat[output][ind] + '.\\n'\n",
        "        else:\n",
        "            out += 'He said \"' + dat[\"utteranceLong\"][ind] + '\" When he said \"' + dat[\"utterance\"][ind] + '\", he used a ' + dat[output][ind] + ' gesture.\\n'\n",
        "        \n",
        "    ## Add question\n",
        "    if not fillin:\n",
        "        out += 'He said \"' + dat[\"utteranceLong\"][i] + '\" When he said \"' + dat[\"utterance\"][i] + '\", he used the following gesture:'\n",
        "    else:\n",
        "        out += 'He said \"' + dat[\"utteranceLong\"][i] + '\" When he said \"' + dat[\"utterance\"][i] + '\", he used a ___  gesture.'\n",
        "    return out\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "def genOneOutputType(df, model, output, num_examples_list = [0, 2, 4, -1], context_list=[True, False], fillin = False, extra_name=\"\", echo = False):\n",
        "    dat_out = []\n",
        "    dat_out.append(list(df[\"utterance\"]))\n",
        "    dat_out.append(list(df[output]))\n",
        "\n",
        "    column_names = [\"Utterance\",\"Annotation\"]\n",
        "    for n in num_examples_list:\n",
        "        for context in context_list:\n",
        "            responses = []\n",
        "            for i in range(df.shape[0]):\n",
        "                prompt = genPrompt(df, i=i, output=output, num_examples=n, examples=[], context=context, fillin=fillin)\n",
        "                time.sleep(2)\n",
        "                response = gptQuery(prompt = prompt, model=model)[0]\n",
        "                responses.append(response)\n",
        "                if echo:\n",
        "                    print(prompt)\n",
        "                    print(\"Response: \" + response + \", Expected Response: \" + df[output][i])\n",
        "                    print(\"\\n\")\n",
        "            dat_out.append(responses)\n",
        "            column_names.append(\"num=\"+str(n)+\"_context=\"+str(context))\n",
        "\n",
        "    df = pd.DataFrame(list(zip(*dat_out)), columns=column_names)\n",
        "    df.to_csv(model+\"_\" +output+extra_name+\".csv\")\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "genOneOutputType(df, CHATGPT, \"GestureType\", [0, 2, 4, 6, -1],  context_list=[True], extra_name=\"-v7\", echo=True)\n",
        "\n",
        "genOneOutputType(df, CHATGPT, \"GestureType\", [0, 2, 4, 6, -1],  context_list=[True], fillin=True, extra_name=\"-v7-fill-in\", echo=True)\n",
        "\n",
        "genOneOutputType(df,CHATGPT, \"PhysicalGesture\", [2, 4, 6, -1], context_list=[True], extra_name=\"-v7\")\n",
        "\n",
        "genOneOutputType(df,CHATGPT, \"SemanticDescription\", [2, 4, 6, -1], context_list=[True], extra_name=\"-v7\")\n",
        "\n",
        "genOneOutputType(df_sweep,CHATGPT, \"PhysicalGesture\", [-1], context_list=[True], extra_name=\"SweepOnly-v7\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "genOneOutputType(df, GPT4, \"GestureType\", [0, 2, 4, 6, -1], context_list=[True], extra_name=\"-v7\", echo=True)\n",
        "\n",
        "genOneOutputType(df, GPT4, \"GestureType\", [0, 2, 4, 6, -1], context_list=[True], fillin=True, extra_name=\"-v7-fill-in\", echo=True)\n",
        "\n",
        "genOneOutputType(df, GPT4, \"PhysicalGesture\", [2, 4, 6, -1], context_list=[True], extra_name=\"-v7\", echo=True)\n",
        "\n",
        "genOneOutputType(df, GPT4, \"SemanticDescription\", [2, 4, 6, -1], context_list=[True], extra_name=\"-v7\")\n",
        "\n",
        "genOneOutputType(df_sweep,GPT4, \"PhysicalGesture\", [-1], context_list=[True], extra_name=\"SweepOnly-v7\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    },
    "vscode": {
      "interpreter": {
        "hash": "bb5ff6be2c42e38762b2676856d251fe1a5f073827e1195963cd8267f1d4f4d0"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
